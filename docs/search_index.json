[["simulations.html", "Chapter 5 Simulations", " Chapter 5 Simulations Pour la description des différents types d’estimation, on a simulé des données selon le DAG suivant (toutes les variables sont binaires): Le code ayant permis de simuler les données est le suivant : rm(list=ls()) param.causal.model &lt;- function(p_L1 = 0.50, p_L2 = 0.20, p_L3 = 0.70, # baseline confounders b_A1 = 0.10, b_L1_A1 = 0.15, b_L2_A1 = 0.25, # modèle de A1 b_A2 = 0.15, b_L1_A2 = 0.20, b_L3_A2 = 0.20, # modèle de A2 b_Y = 0.10, # modèle de Y b_L1_Y = 0.02, b_L2_Y = 0.02, b_L3_Y = -0.02, b_A1_Y = 0.3, b_A2_Y = 0.1, b_A1A2_Y = 0.4 ) { # &lt;- effet d&#39;interaction Delta) # coefficients pour simuler l&#39;exposition # exposition A1 # vérif try(if(b_A1 + b_L1_A1 + b_L1_A1 &gt; 1) stop(&quot;la somme des coefficient du modèle A1 dépasse 100%&quot;)) # exposition A2 # vérif try(if(b_A2 + b_L1_A2 + b_L3_A2 &gt; 1) stop(&quot;la somme des coefficients du modèle A2 dépasse 100%&quot;)) # coefficients pour simuler l&#39;outcome, vérif try(if(b_Y + b_L1_Y + b_L2_Y + b_L3_Y + b_A1_Y + b_A2_Y + b_A1A2_Y &gt; 1) stop(&quot;la somme des coefficients du modèle Y dépasse 100%&quot;)) try(if(b_Y + b_L1_Y + b_L2_Y + b_L3_Y + b_A1_Y + b_A2_Y + b_A1A2_Y &lt; 0) stop(&quot;la somme des coefficients du modèle Y est inférieure à 0%&quot;)) coef &lt;- list(c(p_L1 = p_L1, p_L2 = p_L2, p_L3 = p_L3), c(b_A1 = b_A1, b_L1_A1 = b_L1_A1, b_L2_A1 = b_L2_A1), c(b_A2 = b_A2, b_L1_A2 = b_L1_A2, b_L3_A2 = b_L3_A2), c(b_Y = b_Y, b_L1_Y = b_L1_Y, b_L2_Y = b_L2_Y, b_L3_Y = b_L3_Y, b_A1_Y = b_A1_Y, b_A2_Y = b_A2_Y, b_A1A2_Y = b_A1A2_Y)) return(coef) } generate.data &lt;- function(N, b = param.causal.model()) { L1 &lt;- rbinom(N, size = 1, prob = b[[1]][&quot;p_L1&quot;]) L2 &lt;- rbinom(N, size = 1, prob = b[[1]][&quot;p_L2&quot;]) L3 &lt;- rbinom(N, size = 1, prob = b[[1]][&quot;p_L3&quot;]) A1 &lt;- rbinom(N, size = 1, prob = b[[2]][&quot;b_A1&quot;] + (b[[2]][&quot;b_L1_A1&quot;] * L1) + (b[[2]][&quot;b_L2_A1&quot;] * L2)) A2 &lt;- rbinom(N, size = 1, prob = b[[3]][&quot;b_A2&quot;] + (b[[3]][&quot;b_L1_A2&quot;] * L1) + (b[[3]][&quot;b_L3_A2&quot;] * L3)) Y &lt;- rbinom(N, size = 1, prob = (b[[4]][&quot;b_Y&quot;] + (b[[4]][&quot;b_L1_Y&quot;] * L1) + (b[[4]][&quot;b_L2_Y&quot;] * L2) + (b[[4]][&quot;b_L3_Y&quot;] * L3) + (b[[4]][&quot;b_A1_Y&quot;] * A1) + (b[[4]][&quot;b_A2_Y&quot;] * A2) + (b[[4]][&quot;b_A1A2_Y&quot;] * A1 * A2)) ) data.sim &lt;- data.frame(L1, L2, L3, A1, A2, Y) return(data.sim) } #### On simule une base de données set.seed(12345) # b = param.causal.model(b_A1A2_Y = -0.45) b = param.causal.model() df &lt;- generate.data(N = 10000, b = b) summary(df) prop.table(table(df$Y, df$A1, df$A2, deparse.level = 2)) Au final, les probabilités de l’outcome P(Y=1), dans chaque catégorie sont : A2 label levels value 0 A1 0 0.10 (0.30) 0 1 0.41 (0.49) 1 A1 0 0.20 (0.40) 1 1 0.90 (0.30) "],["a-partir-de-modèles-de-régression.html", "Chapter 6 A partir de modèles de régression 6.1 Régression logistique 6.2 Régression lineaire", " Chapter 6 A partir de modèles de régression Dans une première étape exploratoire, on peut simplement utiliser les modèles de régression habituels. 6.1 Régression logistique Lorsque l’on étudie un outcome binaire, on utilise souvent les modèles de régression logistique. ## ## Call: ## glm(formula = Y ~ as.factor(A1) + as.factor(A2) + as.factor(A1) * ## as.factor(A2) + as.factor(L1) + as.factor(L2) + as.factor(L3), ## family = binomial, data = df_f) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.2419 -0.6580 -0.4678 -0.4341 2.1949 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.16540 0.06708 -32.281 &lt; 2e-16 *** ## as.factor(A1)1 1.75607 0.07604 23.093 &lt; 2e-16 *** ## as.factor(A2)1 0.75332 0.06831 11.028 &lt; 2e-16 *** ## as.factor(L1)1 0.15753 0.05702 2.763 0.00573 ** ## as.factor(L2)1 0.14128 0.06878 2.054 0.03996 * ## as.factor(L3)1 -0.14926 0.06141 -2.431 0.01507 * ## as.factor(A1)1:as.factor(A2)1 1.78587 0.14131 12.638 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 11037.7 on 9999 degrees of freedom ## Residual deviance: 8460.4 on 9993 degrees of freedom ## AIC: 8474.4 ## ## Number of Fisher Scoring iterations: 4 Le coefficient as.factor(A1)1 correspond à l’effet de A1 dans la catégorie de référence de A2, soit \\(\\small OR = exp(1.756) =\\) 5.789. Le coefficient as.factor(A1)1:as.factor(A2)1 correspond à la différence d’effet de A1 quand on passe dans l’autre catégorie de A2. L’effet de A1 dans la catégorie A2=1 est donc \\(\\small OR = exp(1.756+1.786) =\\) 34.536. L’interaction multiplicative peut donc être estimée par \\(\\small IM = exp(1.786) =\\) 5.966, soit \\(\\small OR(A1|A2=0) - OR(A1|A2=1)\\). Ici l’interaction est significative. On aurait aussi pu décrire cette interaction à partir de l’effet d’A2 dans chaque strate de A1. On peut explorer l’interaction sur l’échelle additive en estimant le RERI par \\(\\small RERI \\approx OR_{11} - OR_{10} - OR_{01} + 1 =\\) 28.499, soit \\(\\small OR(A1|A2=0) - OR(A1|A2=1)\\). Ici l’interaction est significative. En résumé (le package finalfit permet de sortir les résultats proprement) : explanatory = c(&quot;as.factor(A1)&quot;, &quot;as.factor(A2)&quot;, &quot;as.factor(A1)*as.factor(A2)&quot;, &quot;as.factor(L1)&quot;, &quot;as.factor(L2)&quot;, &quot;as.factor(L3)&quot;) dependent = &quot;Y&quot; df_f %&gt;% finalfit(dependent, explanatory)-&gt; t cbind(names = c(&quot;A1|A2=0&quot;, &quot;A2|A1=0&quot;, &quot;Interaction&quot;), OR = t[c(12,14,13),6]) %&gt;% as.data.frame %&gt;% kbl() %&gt;% kable_classic() names OR A1|A2=0 5.79 (4.99-6.72, p&lt;0.001) A2|A1=0 2.12 (1.86-2.43, p&lt;0.001) Interaction 5.96 (4.54-7.90, p&lt;0.001) Attention, les modèles de régressions logistiques sont biaisés car les données sont générées à partir de modèles additifs. 6.2 Régression lineaire Même si l’outcome binaire, on peut en théorie utiliser un modèle de régression linéaire et explorer les effets sur une échelle additive. Si l’outcome est quantitatif, on utilise aussi, en général, les modèles de régression linéaire. ## ## Call: ## lm(formula = Y ~ as.factor(A1) + as.factor(A2) + as.factor(A1) * ## as.factor(A2) + as.factor(L1) + as.factor(L2) + as.factor(L3), ## data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.93110 -0.19602 -0.10494 -0.08426 0.91574 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.103835 0.008146 12.746 &lt; 2e-16 *** ## as.factor(A1)1 0.300796 0.011592 25.948 &lt; 2e-16 *** ## as.factor(A2)1 0.092280 0.008671 10.642 &lt; 2e-16 *** ## as.factor(L1)1 0.020677 0.007495 2.759 0.00581 ** ## as.factor(L2)1 0.019476 0.009410 2.070 0.03851 * ## as.factor(L3)1 -0.019574 0.008085 -2.421 0.01549 * ## as.factor(A1)1:as.factor(A2)1 0.394034 0.017854 22.070 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3615 on 9993 degrees of freedom ## Multiple R-squared: 0.2856, Adjusted R-squared: 0.2852 ## F-statistic: 665.8 on 6 and 9993 DF, p-value: &lt; 2.2e-16 partie à compléter names OR A1|A2=0 0.30 (0.28 to 0.32, p&lt;0.001) A2|A1=0 0.09 (0.08 to 0.11, p&lt;0.001) Interaction 0.39 (0.36 to 0.43, p&lt;0.001) "],["analyses-confirmatoires.html", "Chapter 7 Analyses confirmatoires 7.1 Estimation par G-computation 7.2 Estimation par Modèle Structurel Marginal 7.3 Estimation avec TMLE", " Chapter 7 Analyses confirmatoires 7.1 Estimation par G-computation Il s’agit d’une “G-methods” aussi appelée “standardisation” par Hernàn. ## 1.a) on crée 4 tables correspondant aux 4 interventions contrefactuelles df.A1_0.A2_0 &lt;- df.A1_1.A2_0 &lt;- df.A1_0.A2_1 &lt;- df.A1_1.A2_1 &lt;- df df.A1_0.A2_0$A1 &lt;- df.A1_0.A2_0$A2 &lt;- rep(0, nrow(df)) df.A1_1.A2_0$A1 &lt;- rep(1, nrow(df)) df.A1_1.A2_0$A2 &lt;- rep(0, nrow(df)) df.A1_0.A2_1$A1 &lt;- rep(0, nrow(df)) df.A1_0.A2_1$A2 &lt;- rep(1, nrow(df)) df.A1_1.A2_1$A1 &lt;- df.A1_1.A2_1$A2 &lt;- rep(1, nrow(df)) ## 1.b) on modélise le critère de jugement # model.Y &lt;- glm(Y ~ L1 + L2 + L3 + A1 + A2 + A1:A2, data = df, family = &quot;binomial&quot;) # modèle logistique biaisé (il y a des interactions avec les baseline) model.Y &lt;- glm(Y ~ L1 + L2 + L3 + A1 + A2 + A1:A2, data = df, family = &quot;gaussian&quot;) # modèle non biaisé # en pratique la régression logistique n&#39;est pas tellement biaisée, # mais peut être car il n&#39;y a pas la place de mettre beaucoup de confusion # par rapport aux effets importants de A1 et A2 ? (10 fois plus grands) ## 1.c) on prédit le critère de jugement sous les interventions contrefactuelles Y.A1_0.A2_0 &lt;- predict(model.Y, newdata = df.A1_0.A2_0, type = &quot;response&quot;) Y.A1_1.A2_0 &lt;- predict(model.Y, newdata = df.A1_1.A2_0, type = &quot;response&quot;) Y.A1_0.A2_1 &lt;- predict(model.Y, newdata = df.A1_0.A2_1, type = &quot;response&quot;) Y.A1_1.A2_1 &lt;- predict(model.Y, newdata = df.A1_1.A2_1, type = &quot;response&quot;) ## 1.d) on va enregistrer l&#39;ensemble des résultats pertinents dans une table de longueur k1 x k2 int.r &lt;- matrix(NA, ncol = 26, nrow = nlevels(as.factor(df$A1)) * nlevels(as.factor(df$A2))) int.r &lt;- as.data.frame(int.r) names(int.r) &lt;- c(&quot;A1&quot;,&quot;A2&quot;,&quot;p&quot;,&quot;p.lo&quot;,&quot;p.up&quot;, &quot;RD.A1&quot;,&quot;RD.A1.lo&quot;,&quot;RD.A1.up&quot;,&quot;RD.A2&quot;,&quot;RD.A2.lo&quot;,&quot;RD.A2.up&quot;, &quot;RR.A1&quot;,&quot;RR.A1.lo&quot;,&quot;RR.A1.up&quot;,&quot;RR.A2&quot;,&quot;RR.A2.lo&quot;,&quot;RR.A2.up&quot;, &quot;a.INT&quot;, &quot;a.INT.lo&quot;, &quot;a.INT.up&quot;,&quot;RERI&quot;,&quot;RERI.lo&quot;,&quot;RERI.up&quot;, &quot;m.INT&quot;, &quot;m.INT.lo&quot;, &quot;m.INT.up&quot; ) int.r[,c(&quot;A1&quot;,&quot;A2&quot;)] &lt;- expand.grid(c(0,1), c(0,1)) # marginal effects in the k1 x k2 table # A1 = 0 et A2 = 0 int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- mean(Y.A1_0.A2_0) # A1 = 1 et A2 = 0 int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- mean(Y.A1_1.A2_0) # A1 = 0 et A2 = 1 int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_0.A2_1) # A1 = 1 et A2 = 1 int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_1.A2_1) # risk difference # RD.A1.A2is0 int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- mean(Y.A1_1.A2_0) - mean(Y.A1_0.A2_0) # RD.A1.A2is1 int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_1.A2_1) - mean(Y.A1_0.A2_1) # RD.A2.A1is0 int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_0.A2_1) - mean(Y.A1_0.A2_0) # RD.A2.A1is1 int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_1.A2_1) - mean(Y.A1_1.A2_0) # relative risk # RR.A1.A2is0 int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- mean(Y.A1_1.A2_0) / mean(Y.A1_0.A2_0) # RR.A1.A2is1 int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_1.A2_1) / mean(Y.A1_0.A2_1) # RR.A2.A1is0 int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_0.A2_1) / mean(Y.A1_0.A2_0) # RR.A2.A1is1 int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_1.A2_1) / mean(Y.A1_1.A2_0) # additive interaction int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- mean(Y.A1_1.A2_1) - mean(Y.A1_1.A2_0) - mean(Y.A1_0.A2_1) + mean(Y.A1_0.A2_0) # RERI int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- (mean(Y.A1_1.A2_1) - mean(Y.A1_1.A2_0) - mean(Y.A1_0.A2_1) + mean(Y.A1_0.A2_0)) / mean(Y.A1_0.A2_0) # multiplicative interaction int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- (mean(Y.A1_1.A2_1) * mean(Y.A1_0.A2_0)) / (mean(Y.A1_1.A2_0) * mean(Y.A1_0.A2_1)) ## 1.e) Intervalles de confiance par bootstrap set.seed(5678) B &lt;- 2000 bootstrap.est &lt;- data.frame(matrix(NA, nrow = B, ncol = 15)) colnames(bootstrap.est) &lt;- c(&quot;p.A1is0.A2is0&quot;, &quot;p.A1is1.A2is0&quot;, &quot;p.A1is0.A2is1&quot;, &quot;p.A1is1.A2is1&quot;, &quot;RD.A1.A2is0&quot;, &quot;RD.A1.A2is1&quot;, &quot;RD.A2.A1is0&quot;, &quot;RD.A2.A1is1&quot;, &quot;lnRR.A1.A2is0&quot;, &quot;lnRR.A1.A2is1&quot;, &quot;lnRR.A2.A1is0&quot;, &quot;lnRR.A2.A1is1&quot;, &quot;INT.a&quot;, &quot;lnRERI&quot;, &quot;lnINT.m&quot;) for (b in 1:B){ # sample the indices 1 to n with replacement bootIndices &lt;- sample(1:nrow(df), replace=T) bootData &lt;- df[bootIndices,] if ( round(b/100, 0) == b/100 ) print(paste0(&quot;bootstrap number &quot;,b)) # model (unbiased in this case) model.Y &lt;- glm(Y ~ L1 + L2 + L3 + A1 + A2 + A1:A2, data = bootData, # use BootData here +++ family = &quot;gaussian&quot;) # conterfactual data sets boot.A1_0.A2_0 &lt;- boot.A1_1.A2_0 &lt;- boot.A1_0.A2_1 &lt;- boot.A1_1.A2_1 &lt;- bootData boot.A1_0.A2_0$A1 &lt;- boot.A1_0.A2_0$A2 &lt;- rep(0, nrow(df)) boot.A1_1.A2_0$A1 &lt;- rep(1, nrow(df)) boot.A1_1.A2_0$A2 &lt;- rep(0, nrow(df)) boot.A1_0.A2_1$A1 &lt;- rep(0, nrow(df)) boot.A1_0.A2_1$A2 &lt;- rep(1, nrow(df)) boot.A1_1.A2_1$A1 &lt;- boot.A1_1.A2_1$A2 &lt;- rep(1, nrow(df)) # predict potential outcomes under counterfactual scenarios Y.A1_0.A2_0 &lt;- predict(model.Y, newdata = boot.A1_0.A2_0, type = &quot;response&quot;) Y.A1_1.A2_0 &lt;- predict(model.Y, newdata = boot.A1_1.A2_0, type = &quot;response&quot;) Y.A1_0.A2_1 &lt;- predict(model.Y, newdata = boot.A1_0.A2_1, type = &quot;response&quot;) Y.A1_1.A2_1 &lt;- predict(model.Y, newdata = boot.A1_1.A2_1, type = &quot;response&quot;) # save results in the bootstrap table bootstrap.est[b,&quot;p.A1is0.A2is0&quot;] &lt;- mean(Y.A1_0.A2_0) bootstrap.est[b,&quot;p.A1is1.A2is0&quot;] &lt;- mean(Y.A1_1.A2_0) bootstrap.est[b,&quot;p.A1is0.A2is1&quot;] &lt;- mean(Y.A1_0.A2_1) bootstrap.est[b,&quot;p.A1is1.A2is1&quot;] &lt;- mean(Y.A1_1.A2_1) bootstrap.est[b,&quot;RD.A1.A2is0&quot;] &lt;- mean(Y.A1_1.A2_0) - mean(Y.A1_0.A2_0) bootstrap.est[b,&quot;RD.A1.A2is1&quot;] &lt;- mean(Y.A1_1.A2_1) - mean(Y.A1_0.A2_1) bootstrap.est[b,&quot;RD.A2.A1is0&quot;] &lt;- mean(Y.A1_0.A2_1) - mean(Y.A1_0.A2_0) bootstrap.est[b,&quot;RD.A2.A1is1&quot;] &lt;- mean(Y.A1_1.A2_1) - mean(Y.A1_1.A2_0) bootstrap.est[b,&quot;lnRR.A1.A2is0&quot;] &lt;- log(mean(Y.A1_1.A2_0) / mean(Y.A1_0.A2_0)) bootstrap.est[b,&quot;lnRR.A1.A2is1&quot;] &lt;- log(mean(Y.A1_1.A2_1) / mean(Y.A1_0.A2_1)) bootstrap.est[b,&quot;lnRR.A2.A1is0&quot;] &lt;- log(mean(Y.A1_0.A2_1) / mean(Y.A1_0.A2_0)) bootstrap.est[b,&quot;lnRR.A2.A1is1&quot;] &lt;- log(mean(Y.A1_1.A2_1) / mean(Y.A1_1.A2_0)) bootstrap.est[b,&quot;INT.a&quot;] &lt;- mean(Y.A1_1.A2_1) - mean(Y.A1_1.A2_0) - mean(Y.A1_0.A2_1) + mean(Y.A1_0.A2_0) bootstrap.est[b,&quot;lnRERI&quot;] &lt;- log((mean(Y.A1_1.A2_1) - mean(Y.A1_1.A2_0) - mean(Y.A1_0.A2_1) + mean(Y.A1_0.A2_0)) / mean(Y.A1_0.A2_0)) bootstrap.est[b,&quot;lnINT.m&quot;] &lt;- log( (mean(Y.A1_1.A2_1) * mean(Y.A1_0.A2_0)) / (mean(Y.A1_1.A2_0) * mean(Y.A1_0.A2_1))) } # head(bootstrap.est) # summary(bootstrap.est) # par(mfrow = c(4,4)) # for(c in 1:ncol(bootstrap.est)) { # hist(bootstrap.est[,c], freq = FALSE, main = names(bootstrap.est)[c]) # lines(density(bootstrap.est[,c]), col = 2, lwd = 3) # curve(1/sqrt(var(bootstrap.est[,c]) * 2 * pi) * # exp(-1/2 * ((x-mean(bootstrap.est[,c])) / sd(bootstrap.est[,c]))^2), # col = 1, lwd = 2, lty = 2, add = TRUE) # par(mfrow = c(1,1)) # ok, on a des belles lois normales dans les distributions bootstrap, tout va bien ! # pour les IC95%, je peux utiliser la déviation standard des distributions # pour des distributions plus asymétriques, on utiliserait plutôt les percentiles 2.5% et 97.5% # } # marginal effects in the k1 x k2 table # A1 = 0 et A2 = 0 int.r$p.lo[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] - qnorm(0.975) * sd(bootstrap.est$p.A1is0.A2is0) int.r$p.up[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] + qnorm(0.975) * sd(bootstrap.est$p.A1is0.A2is0) # A1 = 1 et A2 = 0 int.r$p.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - qnorm(0.975) * sd(bootstrap.est$p.A1is1.A2is0) int.r$p.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] + qnorm(0.975) * sd(bootstrap.est$p.A1is1.A2is0) # A1 = 0 et A2 = 1 int.r$p.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - qnorm(0.975) * sd(bootstrap.est$p.A1is0.A2is1) int.r$p.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + qnorm(0.975) * sd(bootstrap.est$p.A1is0.A2is1) # A1 = 1 et A2 = 1 int.r$p.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * sd(bootstrap.est$p.A1is1.A2is1) int.r$p.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * sd(bootstrap.est$p.A1is1.A2is1) # risk difference # RD.A1.A2is0 int.r$RD.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] - qnorm(0.975) * sd(bootstrap.est$RD.A1.A2is0) int.r$RD.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] + qnorm(0.975) * sd(bootstrap.est$RD.A1.A2is0) # RD.A1.A2is1 int.r$RD.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * sd(bootstrap.est$RD.A1.A2is1) int.r$RD.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * sd(bootstrap.est$RD.A1.A2is1) # RD.A2.A1is0 int.r$RD.A2.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] - qnorm(0.975) * sd(bootstrap.est$RD.A2.A1is0) int.r$RD.A2.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] + qnorm(0.975) * sd(bootstrap.est$RD.A2.A1is0) # RD.A2.A1is1 int.r$RD.A2.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * sd(bootstrap.est$RD.A2.A1is1) int.r$RD.A2.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * sd(bootstrap.est$RD.A2.A1is1) # relative risk # RR.A1.A2is0 int.r$RR.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) - qnorm(0.975) * sd(bootstrap.est$lnRR.A1.A2is0)) int.r$RR.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) + qnorm(0.975) * sd(bootstrap.est$lnRR.A1.A2is0)) # RR.A1.A2is1 int.r$RR.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * sd(bootstrap.est$lnRR.A1.A2is1)) int.r$RR.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * sd(bootstrap.est$lnRR.A1.A2is1)) # RR.A2.A1is0 int.r$RR.A2.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) - qnorm(0.975) * sd(bootstrap.est$lnRR.A2.A1is0)) int.r$RR.A2.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) + qnorm(0.975) * sd(bootstrap.est$lnRR.A2.A1is0)) # RR.A2.A1is1 int.r$RR.A2.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * sd(bootstrap.est$lnRR.A2.A1is1)) int.r$RR.A2.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * sd(bootstrap.est$lnRR.A2.A1is1)) # additive interaction int.r$a.INT.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * sd(bootstrap.est$INT.a) int.r$a.INT.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * sd(bootstrap.est$INT.a) # RERI int.r$RERI.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * sd(bootstrap.est$lnRERI)) int.r$RERI.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * sd(bootstrap.est$lnRERI)) # multiplicative interaction int.r$m.INT.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * sd(bootstrap.est$lnINT.m)) int.r$m.INT.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * sd(bootstrap.est$lnINT.m)) Au final, on a : A2=0 A2=1 RD.A2|A1 RR.A2|A1 A1=0 \\(p_{00}\\)=0.104 [0.095,0.113] \\(p_{01}\\)=0.197 [0.183,0.211] 0.092 [0.076,0.109] 1.89 [1.68,2.11] A1=1 \\(p_{10}\\)=0.405 [0.379,0.431] \\(p_{11}\\)=0.891 [0.87,0.912] 0.486 [0.453,0.519] 2.2 [2.06,2.36] RD.A1|A2 0.301 [0.273,0.329] 0.695 [0.67,0.72] RR.A1|A2 3.89 [3.48,4.34] 4.54 [4.21,4.89] Note: additive Interaction = 0.394 [0.358;0.43] RERI = 3.78 [3.38;4.23] multiplicative Interaction = 1.17 [1.02;1.33] 7.2 Estimation par Modèle Structurel Marginal # On récupère les Y prédit précédents, que l&#39;on fusionne Y &lt;- c(Y.A1_0.A2_0, Y.A1_1.A2_0, Y.A1_0.A2_1, Y.A1_1.A2_1) length(Y) # on aura une base de données de 40000 lignes # On récupère les valeurs d&#39;exposition qui ont servi dans les scénarios contrefactuels # (garder le même ordre que pour les Y.A1.A2) X &lt;- rbind(subset(df.A1_0.A2_0, select = c(&quot;A1&quot;, &quot;A2&quot;)), subset(df.A1_1.A2_0, select = c(&quot;A1&quot;, &quot;A2&quot;)), subset(df.A1_0.A2_1, select = c(&quot;A1&quot;, &quot;A2&quot;)), subset(df.A1_1.A2_1, select = c(&quot;A1&quot;, &quot;A2&quot;))) # dim(X) ## Modèle structurel marginal msm.RD &lt;- glm(Y ~ A1 + A2 + A1:A2, data = data.frame(Y,X), family = &quot;gaussian&quot;) # ne pas ajuster sur les facteurs de confusion msm.RD ## tableau des effets marignaux results.MSM &lt;- matrix(NA, ncol = 4, nrow = 4) colnames(results.MSM) &lt;- c(&quot;A2 = 0&quot;, &quot;A2 = 1&quot;, &quot;RD within strata of A1&quot;, &quot;RR within strata of A1&quot;) rownames(results.MSM) &lt;- c(&quot;A1 = 0&quot;, &quot;A1 = 1&quot;, &quot;RD within strata of A2&quot;, &quot;RR within strata of A2&quot;) # 4 risques marginaux results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 0&quot;] &lt;- msm.RD$coefficients[&quot;(Intercept)&quot;] results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 1&quot;] &lt;- msm.RD$coefficients[&quot;(Intercept)&quot;] + msm.RD$coefficients[&quot;A2&quot;] results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 0&quot;] &lt;- msm.RD$coefficients[&quot;(Intercept)&quot;] + msm.RD$coefficients[&quot;A1&quot;] results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 1&quot;] &lt;- msm.RD$coefficients[&quot;(Intercept)&quot;] + msm.RD$coefficients[&quot;A2&quot;] + msm.RD$coefficients[&quot;A1&quot;] + msm.RD$coefficients[&quot;A1:A2&quot;] # within strata of A2 results.MSM[&quot;RR within strata of A2&quot;, &quot;A2 = 0&quot;] &lt;- results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 0&quot;] / results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 0&quot;] results.MSM[&quot;RD within strata of A2&quot;, &quot;A2 = 0&quot;] &lt;- results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 0&quot;] - results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 0&quot;] results.MSM[&quot;RR within strata of A2&quot;, &quot;A2 = 1&quot;] &lt;- results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 1&quot;] / results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 1&quot;] results.MSM[&quot;RD within strata of A2&quot;, &quot;A2 = 1&quot;] &lt;- results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 1&quot;] - results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 1&quot;] # within strata of A1 results.MSM[&quot;A1 = 0&quot;, &quot;RR within strata of A1&quot;] &lt;- results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 1&quot;] / results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 0&quot;] results.MSM[&quot;A1 = 0&quot;, &quot;RD within strata of A1&quot;] &lt;- results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 1&quot;] - results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 0&quot;] results.MSM[&quot;A1 = 1&quot;, &quot;RR within strata of A1&quot;] &lt;- results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 1&quot;] / results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 0&quot;] results.MSM[&quot;A1 = 1&quot;, &quot;RD within strata of A1&quot;] &lt;- results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 1&quot;] - results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 0&quot;] results.MSM &lt;- round(results.MSM,3) RD.interaction &lt;- msm.RD$coefficients[&quot;A1:A2&quot;] RR.interaction &lt;- (results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 1&quot;] * results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 0&quot;]) / ( results.MSM[&quot;A1 = 0&quot;,&quot;A2 = 1&quot;] * results.MSM[&quot;A1 = 1&quot;,&quot;A2 = 0&quot;] ) Au final, on a (sans les IC): A2 = 0 A2 = 1 RD within strata of A1 RR within strata of A1 A1 = 0 0.099 0.198 0.099 2.008 A1 = 1 0.409 0.904 0.494 2.208 RD within strata of A2 0.311 0.705 NA NA RR within strata of A2 4.146 4.560 NA NA Note: additive Interaction = 0.395 multiplicative Interaction = 1.11 7.3 Estimation avec TMLE ## 3- int.ltmleMSM() pour estimer les différentes quantités d&#39;intérêt, ### par gcomputation, IPTW ou tmle int.ltmleMSM &lt;- function(data = data, Q_formulas = Q_formulas, g_formulas = g_formulas, Anodes = Anodes, Lnodes = Lnodes, Ynodes = Ynodes, final.Ynodes = final.Ynodes, SL.library = list(Q=&quot;SL.glm&quot;, g=&quot;SL.glm&quot;), gcomp = gcomp, iptw.only = iptw.only, survivalOutcome = FALSE, variance.method = &quot;ic&quot;, B = 2000, boot.seed = 12345) { # regime= # binary array: n x numAnodes x numRegimes of counterfactual treatment or a list of &#39;rule&#39; functions regimes.MSM &lt;- array(NA, dim = c(nrow(data), 2, 4)) # 2 variables d&#39;exposition (A1, A2), 4 régimes d&#39;exposition (0,0) (1,0) (0,1) (1,1) regimes.MSM[,,1] &lt;- matrix(c(0,0), ncol = 2, nrow = nrow(data), byrow = TRUE) # exposé ni à A1, ni à A2 regimes.MSM[,,2] &lt;- matrix(c(1,0), ncol = 2, nrow = nrow(data), byrow = TRUE) # exposé à A1 uniquement regimes.MSM[,,3] &lt;- matrix(c(0,1), ncol = 2, nrow = nrow(data), byrow = TRUE) # exposé à A2 uniquement regimes.MSM[,,4] &lt;- matrix(c(1,1), ncol = 2, nrow = nrow(data), byrow = TRUE) # exposé à A1 et à A2 # summary.measures = valeurs des coefficients du MSM associés à chaque régime # array: num.regimes x num.summary.measures x num.final.Ynodes - # measures summarizing the regimes that will be used on the right hand side of working.msm # (baseline covariates may also be used in the right hand side of working.msm and do not need to be included in summary.measures) summary.measures.reg &lt;- array(NA, dim = c(4, 3, 1)) summary.measures.reg[,,1] &lt;- matrix(c(0, 0, 0, # aucun effet ni de A1, ni de A2 1, 0, 0, # effet de A1 isolé 0, 1, 0, # effet de A2 isolé 1, 1, 1), # effet de A1 + A2 + A1:A2 ncol = 3, nrow = 4, byrow = TRUE) colnames(summary.measures.reg) &lt;- c(&quot;A1&quot;, &quot;A2&quot;, &quot;A1:A2&quot;) if(gcomp == TRUE) { # test length SL.library$Q SL.library$Q &lt;- ifelse(length(SL.library$Q) &gt; 1, &quot;SL.glm&quot;, SL.library$Q) # simplify SL.library$g because g functions are useless with g-computation SL.library$g &lt;- &quot;SL.mean&quot; iptw.only &lt;- FALSE } ltmle_MSM &lt;- ltmleMSM(data = data, Anodes = Anodes, Lnodes = Lnodes, Ynodes = Ynodes, Qform = Q_formulas, gform = g_formulas, #deterministic.g.function = det.g, regimes = regimes.MSM, # à la place de abar working.msm= &quot;Y ~ A1 + A2 + A1:A2&quot;, summary.measures = summary.measures.reg, final.Ynodes = final.Ynodes, msm.weights = NULL, SL.library = SL.library, gcomp = gcomp, iptw.only = iptw.only, survivalOutcome = survivalOutcome, estimate.time = FALSE, variance.method = variance.method) bootstrap.res &lt;- data.frame(&quot;beta.Intercept&quot; = rep(NA, B), &quot;beta.A1&quot; = rep(NA, B), &quot;beta.A2&quot; = rep(NA, B), &quot;beta.A1A2&quot; = rep(NA, B)) if(gcomp == TRUE) { set.seed &lt;- boot.seed for (b in 1:B){ # sample the indices 1 to n with replacement bootIndices &lt;- sample(1:nrow(data), replace=T) bootData &lt;- data[bootIndices,] if ( round(b/100, 0) == b/100 ) print(paste0(&quot;bootstrap number &quot;,b)) boot_ltmle_MSM &lt;- ltmleMSM(data = bootData, Anodes = Anodes, Lnodes = Lnodes, Ynodes = Ynodes, Qform = Q_formulas, gform = g_formulas, #deterministic.g.function = det.g, regimes = regimes.MSM, # à la place de abar working.msm= &quot;Y ~ A1 + A2 + A1:A2&quot;, summary.measures = summary.measures.reg, final.Ynodes = final.Ynodes, msm.weights = NULL, SL.library = SL.library, gcomp = gcomp, iptw.only = iptw.only, survivalOutcome = survivalOutcome, estimate.time = FALSE, variance.method = variance.method) bootstrap.res$beta.Intercept[b] &lt;- boot_ltmle_MSM$beta[&quot;(Intercept)&quot;] bootstrap.res$beta.A1[b] &lt;- boot_ltmle_MSM$beta[&quot;A1&quot;] bootstrap.res$beta.A2[b] &lt;- boot_ltmle_MSM$beta[&quot;A2&quot;] bootstrap.res$beta.A1A2[b] &lt;- boot_ltmle_MSM$beta[&quot;A1:A2&quot;] } } return(list(ltmle_MSM = ltmle_MSM, bootstrap.res = bootstrap.res)) } ### 4- summary.int() pour enregistrer l&#39;ensemble des estimations summary.int &lt;- function(data = data, ltmle_MSM = ltmle_MSM, estimator = c(&quot;gcomp&quot;, &quot;iptw&quot;, &quot;tmle&quot;)) { if(estimator == &quot;gcomp&quot;) { try(if(ltmle_MSM$ltmle_MSM$gcomp == FALSE) stop(&quot;The ltmle function did not use the gcomp estimator, but the iptw +/- tmle estimator&quot;)) beta &lt;- ltmle_MSM$ltmle_MSM$beta } if(estimator == &quot;iptw&quot;) { try(if(ltmle_MSM$ltmle_MSM$gcomp == TRUE) stop(&quot;The ltmle function used the gcomp estimator, iptw is not available&quot;)) beta &lt;- ltmle_MSM$ltmle_MSM$beta.iptw IC &lt;- ltmle_MSM$ltmle_MSM$IC.iptw } if(estimator == &quot;tmle&quot;) { try(if(ltmle_MSM$ltmle_MSM$gcomp == TRUE) stop(&quot;The ltmle function used the gcomp estimator, tmle is not available&quot;)) beta &lt;- ltmle_MSM$ltmle_MSM$beta IC &lt;- ltmle_MSM$ltmle_MSM$IC } # on va enregitrer l&#39;ensemble des résultats pertinent dans une table de longueur k1 x k2 int.r &lt;- matrix(NA, ncol = 34, nrow = nlevels(as.factor(data$A1)) * nlevels(as.factor(data$A2))) int.r &lt;- as.data.frame(int.r) names(int.r) &lt;- c(&quot;A1&quot;,&quot;A2&quot;,&quot;p&quot;,&quot;sd.p&quot;,&quot;p.lo&quot;,&quot;p.up&quot;, &quot;RD.A1&quot;,&quot;sd.RD.A1&quot;,&quot;RD.A1.lo&quot;,&quot;RD.A1.up&quot;, &quot;RD.A2&quot;,&quot;sd.RD.A2&quot;,&quot;RD.A2.lo&quot;,&quot;RD.A2.up&quot;, &quot;RR.A1&quot;,&quot;sd.lnRR.A1&quot;,&quot;RR.A1.lo&quot;,&quot;RR.A1.up&quot;, &quot;RR.A2&quot;,&quot;sd.lnRR.A2&quot;,&quot;RR.A2.lo&quot;,&quot;RR.A2.up&quot;, &quot;a.INT&quot;, &quot;sd.a.INT&quot;, &quot;a.INT.lo&quot;, &quot;a.INT.up&quot;,&quot;RERI&quot;,&quot;sd.lnRERI&quot;,&quot;RERI.lo&quot;,&quot;RERI.up&quot;, &quot;m.INT&quot;, &quot;sd.ln.m.INT&quot;, &quot;m.INT.lo&quot;, &quot;m.INT.up&quot; ) int.r[,c(&quot;A1&quot;,&quot;A2&quot;)] &lt;- expand.grid(c(0,1), c(0,1)) # on peut retrouver les IC95% par delta method # A1 = 0 et A2 = 0 int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- plogis(beta[&quot;(Intercept)&quot;]) # A1 = 1 et A2 = 0 int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- plogis(beta[&quot;(Intercept)&quot;] + beta[&quot;A1&quot;]) # A1 = 0 et A2 = 1 int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- plogis(beta[&quot;(Intercept)&quot;] + beta[&quot;A2&quot;]) # A1 = 1 et A2 = 1 int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- plogis(beta[&quot;(Intercept)&quot;] + beta[&quot;A1&quot;] + beta[&quot;A2&quot;] + beta[&quot;A1:A2&quot;]) # RD.A1.A2is0 int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] # RD.A1.A2is1 int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] # RD.A2.A1is0 int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] # RD.A2.A1is1 int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] # RR.A1.A2is0 int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- exp(log(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]) - log(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0])) # RR.A1.A2is1 int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - log(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1])) # RR.A2.A1is0 int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]) - log(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0])) # RR.A2.A1is1 int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - log(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0])) # additive interaction int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] # RERI int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]) - log(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0])) # multiplicative interaction int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - log(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]) - log(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]) + log(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0])) ## IC95% if(estimator == &quot;iptw&quot; | estimator == &quot;tmle&quot;) { # A1 = 0 et A2 = 0 grad &lt;- c(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]),0,0,0) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- sqrt(v / nrow(data)) int.r$p.lo[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 0] int.r$p.up[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 0] # A1 = 1 et A2 = 0 grad &lt;- c(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]),0,0) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- sqrt(v / nrow(data)) int.r$p.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 0] int.r$p.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 0] # A1 = 0 et A2 = 1 grad &lt;- c(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]), 0, int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]), 0) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$p.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 1] int.r$p.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 1] # A1 = 1 et A2 = 1 grad &lt;- rep(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]), 4) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$p.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$p.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 1] # RD.A1.A2is0 grad &lt;- c(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]), 0, 0) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- sqrt(v / nrow(data)) int.r$RD.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] - qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] int.r$RD.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] + qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] # RD.A1.A2is1 grad &lt;- c(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) ) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$RD.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$RD.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] # RD.A2.A1is0 grad &lt;- c(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]), 0, int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]), 0 ) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$RD.A2.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] int.r$RD.A2.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] # RD.A2.A1is1 grad &lt;- c(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1])) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$RD.A2.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$RD.A2.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] # RR.A1.A2is0 grad &lt;- c(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0], 1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0], 0, 0) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- sqrt(v / nrow(data)) int.r$RR.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) - qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) int.r$RR.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) + qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) # RR.A1.A2is1 grad &lt;- c(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], 1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], 1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] ) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$RR.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1])) int.r$RR.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1])) # RR.A2.A1is0 grad &lt;- c(int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1], 0, 1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1], 0 ) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.lnRR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$RR.A2.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) int.r$RR.A2.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) # RR.A2.A1is1 grad &lt;- c(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], 1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], 1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.lnRR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$RR.A2.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) int.r$RR.A2.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) # additive interaction grad &lt;- c(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]) + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]), int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) ) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$a.INT.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$a.INT.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] # RERI grad &lt;- c((int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1]) + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0])) / (int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]) - (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]), (int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0])) / (int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]), (int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1])) / (int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]), (int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] * (1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1])) / (int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0]) ) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.lnRERI[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$RERI.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.lnRERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) int.r$RERI.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.lnRERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) # multiplicative interaction grad &lt;- c(int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] + int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0], int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1], 1 - int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1]) v &lt;- t(grad) %*% var(IC) %*% grad int.r$sd.ln.m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sqrt(v / nrow(data)) int.r$m.INT.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.ln.m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) int.r$m.INT.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.ln.m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) bootstrap.res &lt;- ltmle_MSM$bootstrap.res } if(estimator == &quot;gcomp&quot;) { ltmle_MSM$bootstrap.res$p.A1_0.A2_0 &lt;- plogis(ltmle_MSM$bootstrap.res$beta.Intercept) ltmle_MSM$bootstrap.res$p.A1_1.A2_0 &lt;- plogis(ltmle_MSM$bootstrap.res$beta.Intercept + ltmle_MSM$bootstrap.res$beta.A1) ltmle_MSM$bootstrap.res$p.A1_0.A2_1 &lt;- plogis(ltmle_MSM$bootstrap.res$beta.Intercept + ltmle_MSM$bootstrap.res$beta.A2) ltmle_MSM$bootstrap.res$p.A1_1.A2_1 &lt;- plogis(ltmle_MSM$bootstrap.res$beta.Intercept + ltmle_MSM$bootstrap.res$beta.A1 + ltmle_MSM$bootstrap.res$beta.A2 + ltmle_MSM$bootstrap.res$beta.A1A2) ltmle_MSM$bootstrap.res$RD.A1.A2_0 &lt;- ltmle_MSM$bootstrap.res$p.A1_1.A2_0 - ltmle_MSM$bootstrap.res$p.A1_0.A2_0 ltmle_MSM$bootstrap.res$RD.A1.A2_1 &lt;- ltmle_MSM$bootstrap.res$p.A1_1.A2_1 - ltmle_MSM$bootstrap.res$p.A1_0.A2_1 ltmle_MSM$bootstrap.res$RD.A2.A1_0 &lt;- ltmle_MSM$bootstrap.res$p.A1_0.A2_1 - ltmle_MSM$bootstrap.res$p.A1_0.A2_0 ltmle_MSM$bootstrap.res$RD.A2.A1_1 &lt;- ltmle_MSM$bootstrap.res$p.A1_1.A2_1 - ltmle_MSM$bootstrap.res$p.A1_1.A2_0 ltmle_MSM$bootstrap.res$lnRR.A1.A2_0 &lt;- log(ltmle_MSM$bootstrap.res$p.A1_1.A2_0 / ltmle_MSM$bootstrap.res$p.A1_0.A2_0) ltmle_MSM$bootstrap.res$lnRR.A1.A2_1 &lt;- log(ltmle_MSM$bootstrap.res$p.A1_1.A2_1 / ltmle_MSM$bootstrap.res$p.A1_0.A2_1) ltmle_MSM$bootstrap.res$lnRR.A2.A1_0 &lt;- log(ltmle_MSM$bootstrap.res$p.A1_0.A2_1 / ltmle_MSM$bootstrap.res$p.A1_0.A2_0) ltmle_MSM$bootstrap.res$lnRR.A2.A1_1 &lt;- log(ltmle_MSM$bootstrap.res$p.A1_1.A2_1 / ltmle_MSM$bootstrap.res$p.A1_1.A2_0) ltmle_MSM$bootstrap.res$a.INT &lt;- ltmle_MSM$bootstrap.res$p.A1_1.A2_1 - ltmle_MSM$bootstrap.res$p.A1_1.A2_0 - ltmle_MSM$bootstrap.res$p.A1_0.A2_1 + ltmle_MSM$bootstrap.res$p.A1_0.A2_0 ltmle_MSM$bootstrap.res$lnRERI &lt;- log((ltmle_MSM$bootstrap.res$p.A1_1.A2_1 - ltmle_MSM$bootstrap.res$p.A1_1.A2_0 - ltmle_MSM$bootstrap.res$p.A1_0.A2_1 + ltmle_MSM$bootstrap.res$p.A1_0.A2_0) / ltmle_MSM$bootstrap.res$p.A1_0.A2_0) ltmle_MSM$bootstrap.res$ln.m.INT &lt;- log((ltmle_MSM$bootstrap.res$p.A1_1.A2_1 * ltmle_MSM$bootstrap.res$p.A1_0.A2_0) / (ltmle_MSM$bootstrap.res$p.A1_1.A2_0 * ltmle_MSM$bootstrap.res$p.A1_0.A2_1)) # A1 = 0 et A2 = 0 int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- sd(ltmle_MSM$bootstrap.res$p.A1_0.A2_0) int.r$p.lo[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 0] int.r$p.up[int.r$A1 == 0 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 0] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 0] # A1 = 1 et A2 = 0 int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- sd(ltmle_MSM$bootstrap.res$p.A1_1.A2_0) int.r$p.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 0] int.r$p.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 0] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 0] # A1 = 0 et A2 = 1 int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$p.A1_0.A2_1) int.r$p.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 1] int.r$p.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 0 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 0 &amp; int.r$A2 == 1] # A1 = 1 et A2 = 1 int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$p.A1_1.A2_1) int.r$p.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$p.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$p[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.p[int.r$A1 == 1 &amp; int.r$A2 == 1] # RD.A1.A2is0 int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- sd(ltmle_MSM$bootstrap.res$RD.A1.A2_0) int.r$RD.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] - qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] int.r$RD.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] + qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] # RD.A1.A2is1 int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$RD.A1.A2_1) int.r$RD.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$RD.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.RD.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] # RD.A2.A1is0 int.r$sd.RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$RD.A2.A1_0) int.r$RD.A2.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] int.r$RD.A2.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] # RD.A2.A1is1 int.r$sd.RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$RD.A2.A1_1) int.r$RD.A2.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$RD.A2.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.RD.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] # RR.A1.A2is0 int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- sd(ltmle_MSM$bootstrap.res$lnRR.A1.A2_0) int.r$RR.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) - qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) int.r$RR.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 0] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) + qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 0]) # RR.A1.A2is1 int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$lnRR.A1.A2_1) int.r$RR.A1.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1])) int.r$RR.A1.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.lnRR.A1[int.r$A1 == 1 &amp; int.r$A2 == 1])) # RR.A2.A1is0 int.r$sd.lnRR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$lnRR.A2.A1_0) int.r$RR.A2.lo[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) int.r$RR.A2.up[int.r$A1 == 0 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 0 &amp; int.r$A2 == 1]) # RR.A2.A1is1 int.r$sd.lnRR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$lnRR.A2.A1_1) int.r$RR.A2.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) int.r$RR.A2.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.lnRR.A2[int.r$A1 == 1 &amp; int.r$A2 == 1]) # additive interaction int.r$sd.a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$a.INT) int.r$a.INT.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] - qnorm(0.975) * int.r$sd.a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] int.r$a.INT.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- int.r$a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] + qnorm(0.975) * int.r$sd.a.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] # RERI int.r$sd.lnRERI[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$lnRERI) int.r$RERI.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.lnRERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) int.r$RERI.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$RERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.lnRERI[int.r$A1 == 1 &amp; int.r$A2 == 1]) # multiplicative interaction int.r$sd.ln.m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- sd(ltmle_MSM$bootstrap.res$ln.m.INT) int.r$m.INT.lo[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) - qnorm(0.975) * int.r$sd.ln.m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) int.r$m.INT.up[int.r$A1 == 1 &amp; int.r$A2 == 1] &lt;- exp(log(int.r$m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) + qnorm(0.975) * int.r$sd.ln.m.INT[int.r$A1 == 1 &amp; int.r$A2 == 1]) bootstrap.res &lt;- ltmle_MSM$bootstrap.res } return(list(int.r = int.r, bootstrap.res = bootstrap.res)) } ### Obtention du MSM par la fonction ltmle, estimation par gcomp, iptw ou tmle # avec la fonction int.ltmleMSM() # on définit les arguments de la fonction ltmleMSM du package ltmle library(ltmle) library(SuperLearner) ## arguments à renseigner Q_formulas = c(Y=&quot;Q.kplus1 ~ L1 + L2 + L3 + A1 * A2&quot;) # useful to add A1 * A2 interaction here g_formulas = c(&quot;A1 ~ L1 + L2&quot;, &quot;A2 ~ L1 + L3&quot;) SL.library = list(Q=list(&quot;SL.glm&quot;, c(&quot;SL.glm&quot;, &quot;screen.corP&quot;), &quot;SL.xgboost&quot;, &quot;SL.rpartPrune&quot;, #&quot;SL.randomForest&quot;, &quot;SL.step.interaction&quot;, c(&quot;SL.step.interaction&quot;,&quot;screen.corP&quot;), &quot;SL.glmnet&quot;, &quot;SL.stepAIC&quot;, &quot;SL.mean&quot;), g=list(&quot;SL.glm&quot;, c(&quot;SL.glm&quot;, &quot;screen.corP&quot;), &quot;SL.xgboost&quot;, &quot;SL.rpartPrune&quot;, #&quot;SL.randomForest&quot;, &quot;SL.step.interaction&quot;, c(&quot;SL.step.interaction&quot;,&quot;screen.corP&quot;), &quot;SL.glmnet&quot;, &quot;SL.stepAIC&quot;, &quot;SL.mean&quot;)) ### estimation par IPTW et TMLE interaction.ltmle &lt;- int.ltmleMSM(data = df, Q_formulas = Q_formulas, g_formulas = g_formulas, Anodes = c(&quot;A1&quot;, &quot;A2&quot;), Lnodes = c(&quot;L1&quot;, &quot;L2&quot;, &quot;L3&quot;), Ynodes = c(&quot;Y&quot;), final.Ynodes = &quot;Y&quot;, SL.library = SL.library, gcomp = FALSE, # si FALSE, fait tmle + IPTW iptw.only = FALSE, # si (gcomp = FALSE et iptw.only = TRUE), fait uniquement iptw survivalOutcome = FALSE, variance.method = &quot;ic&quot;) ### estimation par g-computation # par défaut, il fait une régression logistique à partir de la formule Q_formulas # si on veut faire un régression linéaire pour le modèle additif, on peut créer une fonction de SuperLearner # à partir de la fonction SL.glm SL.glm.gaussian &lt;- function (Y, X, newX, family = &quot;gaussian&quot;, # tout est comme SL.glm, sauf cette famille &quot;gaussian&quot; obsWeights, model = TRUE, ...) { if (is.matrix(X)) { X = as.data.frame(X) } fit.glm &lt;- glm(Y ~ ., data = X, family = family, weights = obsWeights, model = model) if (is.matrix(newX)) { newX = as.data.frame(newX) } pred &lt;- predict(fit.glm, newdata = newX, type = &quot;response&quot;) fit &lt;- list(object = fit.glm) class(fit) &lt;- &quot;SL.glm&quot; out &lt;- list(pred = pred, fit = fit) return(out) } environment(SL.glm.gaussian) &lt;-asNamespace(&quot;SuperLearner&quot;) interaction.gcomp &lt;- int.ltmleMSM(data = df, Q_formulas = Q_formulas, g_formulas = g_formulas, Anodes = c(&quot;A1&quot;, &quot;A2&quot;), Lnodes = c(&quot;L1&quot;, &quot;L2&quot;, &quot;L3&quot;), Ynodes = c(&quot;Y&quot;), final.Ynodes = &quot;Y&quot;, # SL.library = SL.library, SL.library = list(Q=&quot;SL.glm.gaussian&quot;, # g=&quot;SL.mean&quot;), gcomp = TRUE, # si FALSE, fait tmle + IPTW iptw.only = FALSE, # si (gcomp = FALSE et iptw.only = TRUE), fait uniquement iptw survivalOutcome = FALSE, variance.method = &quot;ic&quot;, B = 1000, # nombre d&#39;échantillons bootstrap boot.seed = 54321) # seed pour l&#39;échantillonnage bootstrap ### 3) Calcul des paramètres utiles pour l&#39;analyse de l&#39;interaction # avec la fonction summary.int() ### récupération des résultats tmle summary.tmle &lt;- summary.int(data = df, ltmle_MSM = interaction.ltmle, estimator = c(&quot;tmle&quot;)) # summary.tmle$int.r ### récupération des résultats iptw summary.iptw &lt;- summary.int(data = df, ltmle_MSM = interaction.ltmle, estimator = c(&quot;iptw&quot;)) # summary.iptw$int.r ### récupération des résultats gcomputation summary.gcomp &lt;- summary.int(data = df, ltmle_MSM = interaction.gcomp, estimator = c(&quot;gcomp&quot;)) # summary.gcomp$int.r # head(summary.gcomp$bootstrap.res) # # vérifier la normalité des estimations bootstrap # bootstrap.est &lt;- subset(summary.gcomp$bootstrap.res, # select = # c(&quot;p.A1_0.A2_0&quot;, # &quot;p.A1_1.A2_0&quot;, # &quot;p.A1_0.A2_1&quot;, # &quot;p.A1_1.A2_1&quot;, # &quot;RD.A1.A2_0&quot;, # &quot;RD.A1.A2_1&quot;, # &quot;RD.A2.A1_0&quot;, # &quot;RD.A2.A1_1&quot;, # &quot;lnRR.A1.A2_0&quot;, # &quot;lnRR.A1.A2_1&quot;, # &quot;lnRR.A2.A1_0&quot;, # &quot;lnRR.A2.A1_1&quot;, # &quot;a.INT&quot;, # &quot;lnRERI&quot;, # &quot;ln.m.INT&quot;)) # par(mfrow = c(4,4)) # for(c in 1:ncol(bootstrap.est)) { # hist(bootstrap.est[,c], freq = FALSE, main = names(bootstrap.est)[c]) # lines(density(bootstrap.est[,c]), col = 2, lwd = 3) # curve(1/sqrt(var(bootstrap.est[,c]) * 2 * pi) * exp(-1/2*((x-mean(bootstrap.est[,c]))/sd(bootstrap.est[,c]))^2), # col = 1, lwd = 2, lty = 2, add = TRUE) # par(mfrow = c(1,1)) # } Au final, on a (présentation selon recommandation Knol et al. [1]): 7.3.1 TMLE ## $out.table ## A2=0 A2=1 ## A1=0 $p_{00}$=0.104 [0.095,0.113] $p_{01}$=0.195 [0.18,0.21] ## A1=1 $p_{10}$=0.408 [0.378,0.439] $p_{11}$=0.903 [0.88,0.927] ## RD.A1|A2 0.304 [0.272,0.336] 0.708 [0.68,0.737] ## RR.A1|A2 3.93 [3.5,4.41] 4.63 [4.55,4.72] ## RD.A2|A1 RR.A2|A1 ## A1=0 0.091 [0.073,0.109] 1.88 [1.67,2.11] ## A1=1 0.495 [0.457,0.534] 2.21 [2.04,2.4] ## RD.A1|A2 ## RR.A1|A2 ## ## $interaction.effects ## [1] &quot;additive Interaction = 0.404 [0.362;0.447]&quot; ## [2] &quot;RERI = 3.89 [3.45;4.4]&quot; ## [3] &quot;multiplicative Interaction = 1.18 [1.02;1.36]&quot; 7.3.2 IPTW ## $out.table ## A2=0 A2=1 ## A1=0 $p_{00}$=0.104 [0.095,0.113] $p_{01}$=0.195 [0.18,0.21] ## A1=1 $p_{10}$=0.408 [0.377,0.439] $p_{11}$=0.904 [0.88,0.927] ## RD.A1|A2 0.304 [0.272,0.336] 0.709 [0.68,0.737] ## RR.A1|A2 3.93 [3.5,4.41] 4.63 [4.55,4.72] ## RD.A2|A1 RR.A2|A1 ## A1=0 0.091 [0.073,0.109] 1.88 [1.67,2.11] ## A1=1 0.496 [0.457,0.535] 2.22 [2.05,2.4] ## RD.A1|A2 ## RR.A1|A2 ## ## $interaction.effects ## [1] &quot;additive Interaction = 0.405 [0.362;0.447]&quot; ## [2] &quot;RERI = 3.9 [3.45;4.4]&quot; ## [3] &quot;multiplicative Interaction = 1.18 [1.02;1.36]&quot; 7.3.3 G-computation ## $out.table ## A2=0 A2=1 ## A1=0 $p_{00}$=0.104 [0.095,0.112] $p_{01}$=0.197 [0.183,0.211] ## A1=1 $p_{10}$=0.4 [0.373,0.427] $p_{11}$=0.893 [0.872,0.915] ## RD.A1|A2 0.296 [0.267,0.325] 0.697 [0.671,0.722] ## RR.A1|A2 3.86 [3.45,4.32] 4.54 [4.46,4.61] ## RD.A2|A1 RR.A2|A1 ## A1=0 0.093 [0.076,0.11] 1.9 [1.69,2.13] ## A1=1 0.494 [0.459,0.528] 2.23 [2.08,2.4] ## RD.A1|A2 ## RR.A1|A2 ## ## $interaction.effects ## [1] &quot;additive Interaction = 0.4 [0.362;0.439]&quot; ## [2] &quot;RERI = 3.86 [3.46;4.31]&quot; ## [3] &quot;multiplicative Interaction = 1.18 [1.02;1.35]&quot; Références "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
